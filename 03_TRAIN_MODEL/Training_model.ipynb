{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Train The Model\n",
        "\n",
        "NOTE: Before executing cells **change runtime type > T4 GPU** or any powerful GPU available to you. Because training the model is a very expensive and hardware resources consuming task."
      ],
      "metadata": {
        "id": "hSQiiwZu_Ym5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27fd44e4-6660-46be-a748-c39909828a32",
        "id": "-ZnvAouE_Z8w"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/machine_translation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1R7U_tHcjBd",
        "outputId": "ebf448d5-e4d1-4029-82b8-e70d9514d26a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/machine_translation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVOBlGXH9Hy5",
        "outputId": "cdcee8b4-799c-444e-91da-d78c89fb45b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bible_verses.csv\t\t\t\tMT-Preparation\n",
            "compute-bleu.py\t\t\t\t\tnagamese.csv\n",
            "compute-bleu.py.1\t\t\t\tnagamese.csv-filtered.ng\n",
            "config.yaml\t\t\t\t\tnagamese.csv-filtered.ng.subword\n",
            "english.csv\t\t\t\t\tnagamese.csv-filtered.ng.subword.dev\n",
            "english.csv-filtered.en\t\t\t\tnagamese.csv-filtered.ng.subword.test\n",
            "english.csv-filtered.en.subword\t\t\tnagamese.csv-filtered.ng.subword.test.desubword\n",
            "english.csv-filtered.en.subword.dev\t\tnagamese.csv-filtered.ng.subword.train\n",
            "english.csv-filtered.en.subword.test\t\trun\n",
            "english.csv-filtered.en.subword.test.desubword\tsource.model\n",
            "english.csv-filtered.en.subword.train\t\tsource.vocab\n",
            "en.translated\t\t\t\t\ttarget.model\n",
            "en.translated.desubword\t\t\t\ttarget.vocab\n",
            "models\t\t\t\t\t\ttrain.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [Optional] Check the content of the configuration file\n",
        "!cat config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uR0Skyj814G",
        "outputId": "3c8e27da-0a76-411f-b304-76505ac1900d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# config.yaml\n",
            "\n",
            "save_data: run\n",
            "\n",
            "data:\n",
            "    corpus_1:\n",
            "        path_src: nagamese.csv-filtered.ng.subword.train\n",
            "        path_tgt: english.csv-filtered.en.subword.train\n",
            "        transforms: [filtertoolong]\n",
            "    valid:\n",
            "        path_src: nagamese.csv-filtered.ng.subword.dev\n",
            "        path_tgt: english.csv-filtered.en.subword.dev\n",
            "        transforms: [filtertoolong]\n",
            "\n",
            "src_vocab: run/source.vocab\n",
            "tgt_vocab: run/target.vocab\n",
            "\n",
            "src_vocab_size: 6000\n",
            "tgt_vocab_size: 6000\n",
            "\n",
            "src_seq_length: 150\n",
            "src_seq_length: 150\n",
            "\n",
            "src_subword_model: source.model\n",
            "tgt_subword_model: target.model\n",
            "\n",
            "log_file: train.log\n",
            "save_model: models/model.fren\n",
            "\n",
            "early_stopping: 4\n",
            "\n",
            "# Save a model checkpoint for each n steps\n",
            "save_checkpoint_steps: 500  # More frequent checkpoints due to low dataset size\n",
            "\n",
            "# Limit checkpoints to last n\n",
            "keep_checkpoint: 3\n",
            "\n",
            "seed: 2425\n",
            "\n",
            "# Adjusted training parameters for better efficiency\n",
            "train_steps: 4000        # Extended for deeper learning over limited dataset\n",
            "valid_steps: 500          # More frequent validation for better tracking\n",
            "warmup_steps: 500         # Reduced warm-up as dataset is limited\n",
            "report_every: 100\n",
            "\n",
            "world_size: 1\n",
            "gpu_ranks: [0]\n",
            "\n",
            "# Batching\n",
            "bucket_size: 8192\n",
            "num_workers: 0\n",
            "batch_type: \"tokens\"\n",
            "batch_size: 2048        # Reduced to better handle resource limitations\n",
            "valid_batch_size: 1024  # Reduced to manage validation memory usage\n",
            "max_generator_batches: 2\n",
            "accum_count: [4]\n",
            "accum_steps: [0]\n",
            "\n",
            "# Optimization\n",
            "model_dtype: \"fp16\"\n",
            "optim: \"adam\"\n",
            "learning_rate: 1         # Slightly reduced for stability on small dataset\n",
            "decay_method: \"noam\"\n",
            "adam_beta2: 0.998\n",
            "max_grad_norm: 0\n",
            "label_smoothing: 0.1\n",
            "param_init: 0\n",
            "param_init_glorot: true\n",
            "normalization: \"tokens\"\n",
            "\n",
            "# Model\n",
            "encoder_type: transformer\n",
            "decoder_type: transformer\n",
            "position_encoding: true\n",
            "enc_layers: 6\n",
            "dec_layers: 6\n",
            "heads: 8\n",
            "hidden_size: 512\n",
            "word_vec_size: 512\n",
            "transformer_ff: 2048\n",
            "dropout_steps: [0]\n",
            "dropout: [0.1]\n",
            "self_attn_type: scaled-dot\n",
            "attention_dropout: [0.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the number of CPUs/cores on the machine\n",
        "!nproc --all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgQpVvHbRNuE",
        "outputId": "64dd2030-1455-4ddc-99f0-a821851a04f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the GPU is active\n",
        "!nvidia-smi -h # Check if the GPU is visible to PyTorch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLKKtP5iRVuA",
        "outputId": "743b241c-b0ca-4ea3-e6f4-0de90482b61f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA System Management Interface -- v535.104.05\n",
            "\n",
            "NVSMI provides monitoring information for Tesla and select Quadro devices.\n",
            "The data is presented in either a plain text or an XML format, via stdout or a file.\n",
            "NVSMI also provides several management operations for changing the device state.\n",
            "\n",
            "Note that the functionality of NVSMI is exposed through the NVML C-based\n",
            "library. See the NVIDIA developer website for more information about NVML.\n",
            "Python wrappers to NVML are also available.  The output of NVSMI is\n",
            "not guaranteed to be backwards compatible; NVML and the bindings are backwards\n",
            "compatible.\n",
            "\n",
            "http://developer.nvidia.com/nvidia-management-library-nvml/\n",
            "http://pypi.python.org/pypi/nvidia-ml-py/\n",
            "Supported products:\n",
            "- Full Support\n",
            "    - All Tesla products, starting with the Kepler architecture\n",
            "    - All Quadro products, starting with the Kepler architecture\n",
            "    - All GRID products, starting with the Kepler architecture\n",
            "    - GeForce Titan products, starting with the Kepler architecture\n",
            "- Limited Support\n",
            "    - All Geforce products, starting with the Kepler architecture\n",
            "nvidia-smi [OPTION1 [ARG1]] [OPTION2 [ARG2]] ...\n",
            "\n",
            "    -h,   --help                Print usage information and exit.\n",
            "\n",
            "  LIST OPTIONS:\n",
            "\n",
            "    -L,   --list-gpus           Display a list of GPUs connected to the system.\n",
            "\n",
            "    -B,   --list-excluded-gpus  Display a list of excluded GPUs in the system.\n",
            "\n",
            "  SUMMARY OPTIONS:\n",
            "\n",
            "    <no arguments>              Show a summary of GPUs connected to the system.\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "\n",
            "  QUERY OPTIONS:\n",
            "\n",
            "    -q,   --query               Display GPU or Unit info.\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -u,   --unit                Show unit, rather than GPU, attributes.\n",
            "    -i,   --id=                 Target a specific GPU or Unit.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -x,   --xml-format          Produce XML output.\n",
            "          --dtd                 When showing xml output, embed DTD.\n",
            "    -d,   --display=            Display only selected information: MEMORY,\n",
            "                                    UTILIZATION, ECC, TEMPERATURE, POWER, CLOCK,\n",
            "                                    COMPUTE, PIDS, PERFORMANCE, SUPPORTED_CLOCKS,\n",
            "                                    PAGE_RETIREMENT, ACCOUNTING, ENCODER_STATS,\n",
            "                                    SUPPORTED_GPU_TARGET_TEMP, VOLTAGE\n",
            "                                    FBC_STATS, ROW_REMAPPER, RESET_STATUS\n",
            "                                Flags can be combined with comma e.g. ECC,POWER.\n",
            "                                Sampling data with max/min/avg is also returned \n",
            "                                for POWER, UTILIZATION and CLOCK display types.\n",
            "                                Doesn't work with -u or -x flags.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "\n",
            "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
            "\n",
            "  SELECTIVE QUERY OPTIONS:\n",
            "\n",
            "    Allows the caller to pass an explicit list of properties to query.\n",
            "\n",
            "    [one of]\n",
            "\n",
            "    --query-gpu                 Information about GPU.\n",
            "                                Call --help-query-gpu for more info.\n",
            "    --query-supported-clocks    List of supported clocks.\n",
            "                                Call --help-query-supported-clocks for more info.\n",
            "    --query-compute-apps        List of currently active compute processes.\n",
            "                                Call --help-query-compute-apps for more info.\n",
            "    --query-accounted-apps      List of accounted compute processes.\n",
            "                                Call --help-query-accounted-apps for more info.\n",
            "                                This query is not supported on vGPU host.\n",
            "    --query-retired-pages       List of device memory pages that have been retired.\n",
            "                                Call --help-query-retired-pages for more info.\n",
            "    --query-remapped-rows       Information about remapped rows.\n",
            "                                Call --help-query-remapped-rows for more info.\n",
            "\n",
            "    [mandatory]\n",
            "\n",
            "    --format=                   Comma separated list of format options:\n",
            "                                  csv - comma separated values (MANDATORY)\n",
            "                                  noheader - skip the first line with column headers\n",
            "                                  nounits - don't print units for numerical\n",
            "                                             values\n",
            "\n",
            "    [plus any of]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU or Unit.\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -l,   --loop=               Probe until Ctrl+C at specified second interval.\n",
            "    -lms, --loop-ms=            Probe until Ctrl+C at specified millisecond interval.\n",
            "\n",
            "  DEVICE MODIFICATION OPTIONS:\n",
            "\n",
            "    [any one of]\n",
            "\n",
            "    -pm,  --persistence-mode=   Set persistence mode: 0/DISABLED, 1/ENABLED\n",
            "    -e,   --ecc-config=         Toggle ECC support: 0/DISABLED, 1/ENABLED\n",
            "    -p,   --reset-ecc-errors=   Reset ECC error counts: 0/VOLATILE, 1/AGGREGATE\n",
            "    -c,   --compute-mode=       Set MODE for compute applications:\n",
            "                                0/DEFAULT, 1/EXCLUSIVE_THREAD (DEPRECATED),\n",
            "                                2/PROHIBITED, 3/EXCLUSIVE_PROCESS\n",
            "          --gom=                Set GPU Operation Mode:\n",
            "                                    0/ALL_ON, 1/COMPUTE, 2/LOW_DP\n",
            "    -r    --gpu-reset           Trigger reset of the GPU.\n",
            "                                Can be used to reset the GPU HW state in situations\n",
            "                                that would otherwise require a machine reboot.\n",
            "                                Typically useful if a double bit ECC error has\n",
            "                                occurred.\n",
            "                                Reset operations are not guarenteed to work in\n",
            "                                all cases and should be used with caution.\n",
            "    -vm   --virt-mode=          Switch GPU Virtualization Mode:\n",
            "                                Sets GPU virtualization mode to 3/VGPU or 4/VSGA\n",
            "                                Virtualization mode of a GPU can only be set when\n",
            "                                it is running on a hypervisor.\n",
            "    -lgc  --lock-gpu-clocks=    Specifies <minGpuClock,maxGpuClock> clocks as a\n",
            "                                    pair (e.g. 1500,1500) that defines the range \n",
            "                                    of desired locked GPU clock speed in MHz.\n",
            "                                    Setting this will supercede application clocks\n",
            "                                    and take effect regardless if an app is running.\n",
            "                                    Input can also be a singular desired clock value\n",
            "                                    (e.g. <GpuClockValue>). Optionally, --mode can be\n",
            "                                    specified to indicate a special mode.\n",
            "    -m    --mode=               Specifies the mode for --locked-gpu-clocks.\n",
            "                                    Valid modes: 0, 1\n",
            "    -rgc  --reset-gpu-clocks\n",
            "                                Resets the Gpu clocks to the default values.\n",
            "    -lmc  --lock-memory-clocks=  Specifies <minMemClock,maxMemClock> clocks as a\n",
            "                                    pair (e.g. 5100,5100) that defines the range \n",
            "                                    of desired locked Memory clock speed in MHz.\n",
            "                                    Input can also be a singular desired clock value\n",
            "                                    (e.g. <MemClockValue>).\n",
            "    -rmc  --reset-memory-clocks\n",
            "                                Resets the Memory clocks to the default values.\n",
            "    -lmcd --lock-memory-clocks-deferred=\n",
            "                                    Specifies memClock clock to lock. This limit is\n",
            "                                    applied the next time GPU is initialized.\n",
            "                                    This is guaranteed by unloading and reloading the kernel module.\n",
            "                                    Requires root.\n",
            "    -rmcd --reset-memory-clocks-deferred\n",
            "                                Resets the deferred Memory clocks applied.\n",
            "    -ac   --applications-clocks= Specifies <memory,graphics> clocks as a\n",
            "                                    pair (e.g. 2000,800) that defines GPU's\n",
            "                                    speed in MHz while running applications on a GPU.\n",
            "    -rac  --reset-applications-clocks\n",
            "                                Resets the applications clocks to the default values.\n",
            "    -pl   --power-limit=        Specifies maximum power management limit in watts.\n",
            "                                Takes an optional argument --scope.\n",
            "    -sc   --scope=              Specifies the device type for --scope: 0/GPU, 1/TOTAL_MODULE (Grace Hopper Only)\n",
            "    -cc   --cuda-clocks=        Overrides or restores default CUDA clocks.\n",
            "                                In override mode, GPU clocks higher frequencies when running CUDA applications.\n",
            "                                Only on supported devices starting from the Volta series.\n",
            "                                Requires administrator privileges.\n",
            "                                0/RESTORE_DEFAULT, 1/OVERRIDE\n",
            "    -am   --accounting-mode=    Enable or disable Accounting Mode: 0/DISABLED, 1/ENABLED\n",
            "    -caa  --clear-accounted-apps\n",
            "                                Clears all the accounted PIDs in the buffer.\n",
            "          --auto-boost-default= Set the default auto boost policy to 0/DISABLED\n",
            "                                or 1/ENABLED, enforcing the change only after the\n",
            "                                last boost client has exited.\n",
            "          --auto-boost-permission=\n",
            "                                Allow non-admin/root control over auto boost mode:\n",
            "                                0/UNRESTRICTED, 1/RESTRICTED\n",
            "    -mig  --multi-instance-gpu= Enable or disable Multi Instance GPU: 0/DISABLED, 1/ENABLED\n",
            "                                Requires root.\n",
            "    -gtt  --gpu-target-temp=    Set GPU Target Temperature for a GPU in degree celsius.\n",
            "                                Requires administrator privileges\n",
            "\n",
            "   [plus optional]\n",
            "\n",
            "    -i,   --id=                 Target a specific GPU.\n",
            "    -eow, --error-on-warning    Return a non-zero error for warnings.\n",
            "\n",
            "  UNIT MODIFICATION OPTIONS:\n",
            "\n",
            "    -t,   --toggle-led=         Set Unit LED state: 0/GREEN, 1/AMBER\n",
            "\n",
            "   [plus optional]\n",
            "\n",
            "    -i,   --id=                 Target a specific Unit.\n",
            "\n",
            "  SHOW DTD OPTIONS:\n",
            "\n",
            "          --dtd                 Print device DTD and exit.\n",
            "\n",
            "     [plus optional]\n",
            "\n",
            "    -f,   --filename=           Log to a specified file, rather than to stdout.\n",
            "    -u,   --unit                Show unit, rather than device, DTD.\n",
            "\n",
            "    --debug=                    Log encrypted debug information to a specified file. \n",
            "\n",
            " Device Monitoring:\n",
            "    dmon                        Displays device stats in scrolling format.\n",
            "                                \"nvidia-smi dmon -h\" for more information.\n",
            "\n",
            "    daemon                      Runs in background and monitor devices as a daemon process.\n",
            "                                This is an experimental feature. Not supported on Windows baremetal\n",
            "                                \"nvidia-smi daemon -h\" for more information.\n",
            "\n",
            "    replay                      Used to replay/extract the persistent stats generated by daemon.\n",
            "                                This is an experimental feature.\n",
            "                                \"nvidia-smi replay -h\" for more information.\n",
            "\n",
            " Process Monitoring:\n",
            "    pmon                        Displays process stats in scrolling format.\n",
            "                                \"nvidia-smi pmon -h\" for more information.\n",
            "\n",
            " TOPOLOGY:\n",
            "    topo                        Displays device/system topology. \"nvidia-smi topo -h\" for more information.\n",
            "\n",
            " DRAIN STATES:\n",
            "    drain                       Displays/modifies GPU drain states for power idling. \"nvidia-smi drain -h\" for more information.\n",
            "\n",
            " NVLINK:\n",
            "    nvlink                      Displays device nvlink information. \"nvidia-smi nvlink -h\" for more information.\n",
            "\n",
            " C2C:\n",
            "    c2c                         Displays device C2C information. \"nvidia-smi c2c -h\" for more information.\n",
            "\n",
            " CLOCKS:\n",
            "    clocks                      Control and query clock information. \"nvidia-smi clocks -h\" for more information.\n",
            "\n",
            " ENCODER SESSIONS:\n",
            "    encodersessions             Displays device encoder sessions information. \"nvidia-smi encodersessions -h\" for more information.\n",
            "\n",
            " FBC SESSIONS:\n",
            "    fbcsessions                 Displays device FBC sessions information. \"nvidia-smi fbcsessions -h\" for more information.\n",
            "\n",
            " GRID vGPU:\n",
            "    vgpu                        Displays vGPU information. \"nvidia-smi vgpu -h\" for more information.\n",
            "\n",
            " MIG:\n",
            "    mig                         Provides controls for MIG management. \"nvidia-smi mig -h\" for more information.\n",
            "\n",
            " COMPUTE POLICY:\n",
            "    compute-policy              Control and query compute policies. \"nvidia-smi compute-policy -h\" for more information. \n",
            "\n",
            " BOOST SLIDER:\n",
            "    boost-slider                Control and query boost sliders. \"nvidia-smi boost-slider -h\" for more information. \n",
            "\n",
            " POWER HINT:    power-hint                  Estimates GPU power usage. \"nvidia-smi power-hint -h\" for more information. \n",
            "\n",
            " BASE CLOCKS:    base-clocks                 Query GPU base clocks. \"nvidia-smi base-clocks -h\" for more information. \n",
            "\n",
            " CONFIDENTIAL COMPUTE:\n",
            "    conf-compute                Control and query confidential compute. \"nvidia-smi conf-compute -h\" for more information. \n",
            "\n",
            " GPU PERFORMANCE MONITORING: \n",
            "    gpm                         Control and query GPU performance monitoring unit. \"nvidia-smi gpm -h\" for more information. \n",
            "\n",
            "Please see the nvidia-smi(1) manual page for more detailed information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --list-gpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbL4B4Z_YJGQ",
        "outputId": "9f01c532-cea6-40f9-d27a-c3c7e089084e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-73c4ef44-53f8-67ba-dfc5-f77896c2686f)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "gpu_memory = torch.cuda.mem_get_info(0)\n",
        "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4VZ5uKMXhJ5",
        "outputId": "c2ed8e61-2058-4a01-8bdf-e8abbcfebeea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n",
            "Free GPU memory: 14999.0625 out of: 15102.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv6Ij-XcYf6M",
        "outputId": "79923b0e-7333-41cf-a214-8d4e1e1d3445"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/machine_translation\n",
            "bible_verses.csv\t\t\t\tMT-Preparation\n",
            "compute-bleu.py\t\t\t\t\tnagamese.csv\n",
            "compute-bleu.py.1\t\t\t\tnagamese.csv-filtered.ng\n",
            "config.yaml\t\t\t\t\tnagamese.csv-filtered.ng.subword\n",
            "english.csv\t\t\t\t\tnagamese.csv-filtered.ng.subword.dev\n",
            "english.csv-filtered.en\t\t\t\tnagamese.csv-filtered.ng.subword.test\n",
            "english.csv-filtered.en.subword\t\t\tnagamese.csv-filtered.ng.subword.test.desubword\n",
            "english.csv-filtered.en.subword.dev\t\tnagamese.csv-filtered.ng.subword.train\n",
            "english.csv-filtered.en.subword.test\t\trun\n",
            "english.csv-filtered.en.subword.test.desubword\tsource.model\n",
            "english.csv-filtered.en.subword.train\t\tsource.vocab\n",
            "en.translated\t\t\t\t\ttarget.model\n",
            "en.translated.desubword\t\t\t\ttarget.vocab\n",
            "models\t\t\t\t\t\ttrain.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!rm -rf drive/MyDrive/machine_translation/models/"
      ],
      "metadata": {
        "id": "vRO-am8xYirW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install OpenNMT-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EZOASdGNdful",
        "outputId": "7cf91ac1-99c0-476a-d7fa-4e11bc308516"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting OpenNMT-py\n",
            "  Downloading OpenNMT_py-3.5.1-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting torch<2.3,>=2.1 (from OpenNMT-py)\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting configargparse (from OpenNMT-py)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ctranslate2<5,>=4 (from OpenNMT-py)\n",
            "  Downloading ctranslate2-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.17.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.2.5)\n",
            "Collecting waitress (from OpenNMT-py)\n",
            "  Downloading waitress-3.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pyonmttok<2,>=1.37 (from OpenNMT-py)\n",
            "  Downloading pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (6.0.2)\n",
            "Collecting sacrebleu (from OpenNMT-py)\n",
            "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz (from OpenNMT-py)\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pyahocorasick (from OpenNMT-py)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (13 kB)\n",
            "Collecting fasttext-wheel (from OpenNMT-py)\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (3.7.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4->OpenNMT-py) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<5,>=4->OpenNMT-py) (1.26.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.20.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.0.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.3,>=2.1->OpenNMT-py) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch<2.3,>=2.1->OpenNMT-py)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3,>=2.1->OpenNMT-py) (12.6.77)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel->OpenNMT-py)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (8.1.7)\n",
            "Collecting portalocker (from sacrebleu->OpenNMT-py)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (2024.9.11)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->OpenNMT-py)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (5.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.9.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.3,>=2.1->OpenNMT-py) (3.0.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->OpenNMT-py) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->OpenNMT-py) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->OpenNMT-py) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->OpenNMT-py) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->OpenNMT-py) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (13.9.3)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->OpenNMT-py) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->OpenNMT-py) (7.0.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.3,>=2.1->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->OpenNMT-py) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->OpenNMT-py) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->OpenNMT-py) (0.1.2)\n",
            "Downloading OpenNMT_py-3.5.1-py3-none-any.whl (262 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.8/262.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading waitress-3.0.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: waitress, triton, rapidfuzz, pyonmttok, pybind11, pyahocorasick, portalocker, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ctranslate2, configargparse, colorama, sacrebleu, nvidia-cusolver-cu12, nvidia-cudnn-cu12, fasttext-wheel, torch, OpenNMT-py\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "      Successfully uninstalled torch-2.5.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.2.2 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed OpenNMT-py-3.5.1 colorama-0.4.6 configargparse-1.7 ctranslate2-4.5.0 fasttext-wheel-0.9.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 portalocker-2.10.1 pyahocorasick-2.1.0 pybind11-2.13.6 pyonmttok-1.37.1 rapidfuzz-3.10.1 sacrebleu-2.4.3 torch-2.2.2 triton-2.2.0 waitress-3.0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "f79701b03b584c509e5d41c31ea77869"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the NMT model\n",
        "!onmt_train -config config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhEDHIZZdtK6",
        "outputId": "7cddb140-4966-497d-8e2f-956b262646c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-11-09 16:16:16,574 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2024-11-09 16:16:16,870 INFO] Parsed 2 corpora from -data.\n",
            "[2024-11-09 16:16:16,872 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
            "[2024-11-09 16:16:17,555 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', ',', '▁', '▁laga', '.', '\"', '▁\"']\n",
            "[2024-11-09 16:16:17,555 INFO] The decoder start token is: <s>\n",
            "[2024-11-09 16:16:17,555 INFO] Building model...\n",
            "[2024-11-09 16:16:20,061 INFO] Switching model to float32 for amp/apex_amp\n",
            "[2024-11-09 16:16:20,061 INFO] Non quantized layer compute is fp16\n",
            "[2024-11-09 16:16:20,252 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(2168, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-5): 6 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(4024, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-5): 6 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=512, out_features=4024, bias=True)\n",
            ")\n",
            "[2024-11-09 16:16:20,255 INFO] encoder: 19997696\n",
            "[2024-11-09 16:16:20,256 INFO] decoder: 29309880\n",
            "[2024-11-09 16:16:20,256 INFO] * number of parameters: 49307576\n",
            "[2024-11-09 16:16:20,257 INFO] Trainable parameters = {'torch.float32': 49307576, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2024-11-09 16:16:20,257 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2024-11-09 16:16:20,257 INFO]  * src vocab size = 2168\n",
            "[2024-11-09 16:16:20,257 INFO]  * tgt vocab size = 4024\n",
            "[2024-11-09 16:16:20,558 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2024-11-09 16:16:20,559 INFO] Starting training on GPU: [0]\n",
            "[2024-11-09 16:16:20,559 INFO] Start training loop and validate every 500 steps...\n",
            "[2024-11-09 16:16:20,559 INFO] Scoring with: ['filtertoolong']\n",
            "[2024-11-09 16:16:21,753 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2024-11-09 16:16:21,916 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2024-11-09 16:16:29,625 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 4\n",
            "[2024-11-09 16:16:29,974 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 5\n",
            "[2024-11-09 16:16:36,100 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 6\n",
            "[2024-11-09 16:16:36,246 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 7\n",
            "[2024-11-09 16:16:36,585 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 8\n",
            "[2024-11-09 16:16:43,241 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 9\n",
            "[2024-11-09 16:16:43,595 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 10\n",
            "[2024-11-09 16:16:49,753 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 11\n",
            "[2024-11-09 16:16:49,908 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 12\n",
            "[2024-11-09 16:16:56,317 INFO] Step 100/ 4000; acc: 14.9; ppl: 485.1; xent: 6.2; lr: 0.00040; sents:   17392; bsz: 1560/1459/43; 17449/16323 tok/s;     36 sec;\n",
            "[2024-11-09 16:16:57,956 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 13\n",
            "[2024-11-09 16:16:58,119 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 14\n",
            "[2024-11-09 16:16:58,261 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 15\n",
            "[2024-11-09 16:17:04,669 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 16\n",
            "[2024-11-09 16:17:04,812 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 17\n",
            "[2024-11-09 16:17:11,858 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 18\n",
            "[2024-11-09 16:17:12,007 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 19\n",
            "[2024-11-09 16:17:12,158 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 20\n",
            "[2024-11-09 16:17:18,609 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 21\n",
            "[2024-11-09 16:17:18,763 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 22\n",
            "[2024-11-09 16:17:25,735 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 23\n",
            "[2024-11-09 16:17:25,882 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 24\n",
            "[2024-11-09 16:17:29,572 INFO] Step 200/ 4000; acc: 33.5; ppl:  76.5; xent: 4.3; lr: 0.00079; sents:   17271; bsz: 1555/1452/43; 18710/17466 tok/s;     69 sec;\n",
            "[2024-11-09 16:17:32,309 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 25\n",
            "[2024-11-09 16:17:32,454 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 26\n",
            "[2024-11-09 16:17:32,600 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 27\n",
            "[2024-11-09 16:17:39,592 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 28\n",
            "[2024-11-09 16:17:39,738 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 29\n",
            "[2024-11-09 16:17:45,983 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 30\n",
            "[2024-11-09 16:17:46,316 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 31\n",
            "[2024-11-09 16:17:46,462 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 32\n",
            "[2024-11-09 16:17:53,480 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 33\n",
            "[2024-11-09 16:17:53,624 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 34\n",
            "[2024-11-09 16:17:59,911 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 35\n",
            "[2024-11-09 16:18:00,263 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 36\n",
            "[2024-11-09 16:18:02,453 INFO] Step 300/ 4000; acc: 48.1; ppl:  30.3; xent: 3.4; lr: 0.00119; sents:   17372; bsz: 1557/1456/43; 18938/17717 tok/s;    102 sec;\n",
            "[2024-11-09 16:18:07,111 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 37\n",
            "[2024-11-09 16:18:07,260 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 38\n",
            "[2024-11-09 16:18:07,621 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 39\n",
            "[2024-11-09 16:18:13,886 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 40\n",
            "[2024-11-09 16:18:14,032 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 41\n",
            "[2024-11-09 16:18:21,076 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 42\n",
            "[2024-11-09 16:18:21,229 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 43\n",
            "[2024-11-09 16:18:21,599 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 44\n",
            "[2024-11-09 16:18:27,906 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 45\n",
            "[2024-11-09 16:18:28,051 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 46\n",
            "[2024-11-09 16:18:35,059 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 47\n",
            "[2024-11-09 16:18:35,205 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 48\n",
            "[2024-11-09 16:18:36,164 INFO] Step 400/ 4000; acc: 65.7; ppl:  12.7; xent: 2.5; lr: 0.00159; sents:   17285; bsz: 1557/1455/43; 18474/17261 tok/s;    136 sec;\n",
            "[2024-11-09 16:18:41,751 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 49\n",
            "[2024-11-09 16:18:41,901 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 50\n",
            "[2024-11-09 16:18:42,048 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 51\n",
            "[2024-11-09 16:18:49,117 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 52\n",
            "[2024-11-09 16:18:49,262 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 53\n",
            "[2024-11-09 16:18:55,785 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 54\n",
            "[2024-11-09 16:18:55,934 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 55\n",
            "[2024-11-09 16:18:56,091 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 56\n",
            "[2024-11-09 16:19:03,139 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 57\n",
            "[2024-11-09 16:19:03,309 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 58\n",
            "[2024-11-09 16:19:08,513 INFO] Step 500/ 4000; acc: 81.3; ppl:   7.0; xent: 1.9; lr: 0.00197; sents:   17301; bsz: 1555/1453/43; 19234/17972 tok/s;    168 sec;\n",
            "[2024-11-09 16:19:09,782 INFO] valid stats calculation\n",
            "                           took: 1.2674248218536377 s.\n",
            "[2024-11-09 16:19:09,783 INFO] Train perplexity: 39.8351\n",
            "[2024-11-09 16:19:09,783 INFO] Train accuracy: 48.6703\n",
            "[2024-11-09 16:19:09,783 INFO] Sentences processed: 86621\n",
            "[2024-11-09 16:19:09,783 INFO] Average bsz: 1557/1455/43\n",
            "[2024-11-09 16:19:09,783 INFO] Validation perplexity: 129.554\n",
            "[2024-11-09 16:19:09,783 INFO] Validation accuracy: 37.3123\n",
            "[2024-11-09 16:19:09,783 INFO] Model is improving ppl: inf --> 129.554.\n",
            "[2024-11-09 16:19:09,783 INFO] Model is improving acc: -inf --> 37.3123.\n",
            "[2024-11-09 16:19:09,786 INFO] Saving checkpoint models/model.fren_step_500.pt\n",
            "[2024-11-09 16:19:14,013 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 59\n",
            "[2024-11-09 16:19:14,215 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 60\n",
            "[2024-11-09 16:19:20,843 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 61\n",
            "[2024-11-09 16:19:21,497 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 62\n",
            "[2024-11-09 16:19:21,825 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 63\n",
            "[2024-11-09 16:19:31,056 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 64\n",
            "[2024-11-09 16:19:31,421 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 65\n",
            "[2024-11-09 16:19:37,821 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 66\n",
            "[2024-11-09 16:19:38,179 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 67\n",
            "[2024-11-09 16:19:38,328 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 68\n",
            "[2024-11-09 16:19:45,281 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 69\n",
            "[2024-11-09 16:19:45,648 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 70\n",
            "[2024-11-09 16:19:49,437 INFO] Step 600/ 4000; acc: 90.3; ppl:   5.1; xent: 1.6; lr: 0.00180; sents:   17419; bsz: 1558/1457/44; 15233/14240 tok/s;    209 sec;\n",
            "[2024-11-09 16:19:52,047 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 71\n",
            "[2024-11-09 16:19:52,310 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 72\n",
            "[2024-11-09 16:19:59,559 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 73\n",
            "[2024-11-09 16:19:59,704 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 74\n",
            "[2024-11-09 16:19:59,852 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 75\n",
            "[2024-11-09 16:20:06,649 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 76\n",
            "[2024-11-09 16:20:06,917 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 77\n",
            "[2024-11-09 16:20:14,110 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 78\n",
            "[2024-11-09 16:20:14,259 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 79\n",
            "[2024-11-09 16:20:14,402 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 80\n",
            "[2024-11-09 16:20:21,312 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 81\n",
            "[2024-11-09 16:20:21,562 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 82\n",
            "[2024-11-09 16:20:24,515 INFO] Step 700/ 4000; acc: 95.9; ppl:   4.2; xent: 1.4; lr: 0.00167; sents:   17293; bsz: 1557/1456/43; 17751/16607 tok/s;    244 sec;\n",
            "[2024-11-09 16:20:28,556 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 83\n",
            "[2024-11-09 16:20:28,707 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 84\n",
            "[2024-11-09 16:20:35,655 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 85\n",
            "[2024-11-09 16:20:35,923 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 86\n",
            "[2024-11-09 16:20:36,176 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 87\n",
            "[2024-11-09 16:20:43,027 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 88\n",
            "[2024-11-09 16:20:43,173 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 89\n",
            "[2024-11-09 16:20:50,308 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 90\n",
            "[2024-11-09 16:20:50,500 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 91\n",
            "[2024-11-09 16:20:50,652 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 92\n",
            "[2024-11-09 16:20:57,318 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 93\n",
            "[2024-11-09 16:20:57,469 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 94\n",
            "[2024-11-09 16:20:58,432 INFO] Step 800/ 4000; acc: 97.9; ppl:   3.9; xent: 1.4; lr: 0.00156; sents:   17279; bsz: 1557/1453/43; 18361/17133 tok/s;    278 sec;\n",
            "[2024-11-09 16:21:04,516 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 95\n",
            "[2024-11-09 16:21:04,872 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 96\n",
            "[2024-11-09 16:21:11,261 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 97\n",
            "[2024-11-09 16:21:11,411 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 98\n",
            "[2024-11-09 16:21:11,774 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 99\n",
            "[2024-11-09 16:21:18,680 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 100\n",
            "[2024-11-09 16:21:19,058 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 101\n",
            "[2024-11-09 16:21:25,470 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 102\n",
            "[2024-11-09 16:21:25,616 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 103\n",
            "[2024-11-09 16:21:31,852 INFO] Step 900/ 4000; acc: 98.7; ppl:   3.7; xent: 1.3; lr: 0.00147; sents:   17346; bsz: 1558/1456/43; 18644/17422 tok/s;    311 sec;\n",
            "[2024-11-09 16:21:32,697 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 104\n",
            "[2024-11-09 16:21:32,849 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 105\n",
            "[2024-11-09 16:21:33,006 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 106\n",
            "[2024-11-09 16:21:40,204 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 107\n",
            "[2024-11-09 16:21:40,366 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 108\n",
            "[2024-11-09 16:21:47,467 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 109\n",
            "[2024-11-09 16:21:47,619 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 110\n",
            "[2024-11-09 16:21:47,769 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 111\n",
            "[2024-11-09 16:21:54,438 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 112\n",
            "[2024-11-09 16:21:54,585 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 113\n",
            "[2024-11-09 16:22:01,734 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 114\n",
            "[2024-11-09 16:22:01,883 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 115\n",
            "[2024-11-09 16:22:06,040 INFO] Step 1000/ 4000; acc: 99.0; ppl:   3.6; xent: 1.3; lr: 0.00140; sents:   17393; bsz: 1554/1453/43; 18186/17005 tok/s;    345 sec;\n",
            "[2024-11-09 16:22:06,587 INFO] valid stats calculation\n",
            "                           took: 0.5453903675079346 s.\n",
            "[2024-11-09 16:22:06,588 INFO] Train perplexity: 12.7835\n",
            "[2024-11-09 16:22:06,588 INFO] Train accuracy: 72.5105\n",
            "[2024-11-09 16:22:06,588 INFO] Sentences processed: 173351\n",
            "[2024-11-09 16:22:06,588 INFO] Average bsz: 1557/1455/43\n",
            "[2024-11-09 16:22:06,588 INFO] Validation perplexity: 143.395\n",
            "[2024-11-09 16:22:06,588 INFO] Validation accuracy: 38.6406\n",
            "[2024-11-09 16:22:06,589 INFO] Stalled patience: 3/4\n",
            "[2024-11-09 16:22:06,591 INFO] Saving checkpoint models/model.fren_step_1000.pt\n",
            "[2024-11-09 16:22:11,470 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 116\n",
            "[2024-11-09 16:22:11,739 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 117\n",
            "[2024-11-09 16:22:12,010 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 118\n",
            "[2024-11-09 16:22:20,308 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 119\n",
            "[2024-11-09 16:22:20,599 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 120\n",
            "[2024-11-09 16:22:28,794 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 121\n",
            "[2024-11-09 16:22:29,139 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 122\n",
            "[2024-11-09 16:22:29,288 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 123\n",
            "[2024-11-09 16:22:35,921 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 124\n",
            "[2024-11-09 16:22:36,068 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 125\n",
            "[2024-11-09 16:22:43,114 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 126\n",
            "[2024-11-09 16:22:43,474 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 127\n",
            "[2024-11-09 16:22:46,217 INFO] Step 1100/ 4000; acc: 99.2; ppl:   3.6; xent: 1.3; lr: 0.00133; sents:   17226; bsz: 1561/1458/43; 15537/14519 tok/s;    386 sec;\n",
            "[2024-11-09 16:22:49,921 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 128\n",
            "[2024-11-09 16:22:50,200 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 129\n",
            "[2024-11-09 16:22:50,726 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 130\n",
            "[2024-11-09 16:22:57,708 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 131\n",
            "[2024-11-09 16:22:57,855 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 132\n",
            "[2024-11-09 16:23:04,678 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 133\n",
            "[2024-11-09 16:23:04,957 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 134\n",
            "[2024-11-09 16:23:05,514 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 135\n",
            "[2024-11-09 16:23:12,360 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 136\n",
            "[2024-11-09 16:23:12,504 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 137\n",
            "[2024-11-09 16:23:19,430 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 138\n",
            "[2024-11-09 16:23:19,723 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 139\n",
            "[2024-11-09 16:23:21,680 INFO] Step 1200/ 4000; acc: 99.2; ppl:   3.6; xent: 1.3; lr: 0.00128; sents:   17321; bsz: 1556/1453/43; 17545/16394 tok/s;    421 sec;\n",
            "[2024-11-09 16:23:26,790 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 140\n",
            "[2024-11-09 16:23:26,939 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 141\n",
            "[2024-11-09 16:23:27,093 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 142\n",
            "[2024-11-09 16:23:34,206 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 143\n",
            "[2024-11-09 16:23:34,465 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 144\n",
            "[2024-11-09 16:23:41,245 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 145\n",
            "[2024-11-09 16:23:41,395 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 146\n",
            "[2024-11-09 16:23:41,544 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 147\n",
            "[2024-11-09 16:23:48,664 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 148\n",
            "[2024-11-09 16:23:48,814 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 149\n",
            "[2024-11-09 16:23:54,618 INFO] Step 1300/ 4000; acc: 99.3; ppl:   3.5; xent: 1.3; lr: 0.00123; sents:   17403; bsz: 1553/1454/44; 18863/17655 tok/s;    454 sec;\n",
            "[2024-11-09 16:23:55,478 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 150\n",
            "[2024-11-09 16:23:55,629 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 151\n",
            "[2024-11-09 16:24:02,560 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 152\n",
            "[2024-11-09 16:24:02,915 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 153\n",
            "[2024-11-09 16:24:03,064 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 154\n",
            "[2024-11-09 16:24:09,535 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 155\n",
            "[2024-11-09 16:24:09,915 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 156\n",
            "[2024-11-09 16:24:16,855 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 157\n",
            "[2024-11-09 16:24:17,000 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 158\n",
            "[2024-11-09 16:24:17,366 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 159\n",
            "[2024-11-09 16:24:23,833 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 160\n",
            "[2024-11-09 16:24:24,201 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 161\n",
            "[2024-11-09 16:24:29,026 INFO] Step 1400/ 4000; acc: 99.3; ppl:   3.5; xent: 1.3; lr: 0.00118; sents:   17317; bsz: 1559/1455/43; 18121/16918 tok/s;    488 sec;\n",
            "[2024-11-09 16:24:31,145 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 162\n",
            "[2024-11-09 16:24:31,292 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 163\n",
            "[2024-11-09 16:24:37,982 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 164\n",
            "[2024-11-09 16:24:38,129 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 165\n",
            "[2024-11-09 16:24:38,291 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 166\n",
            "[2024-11-09 16:24:45,513 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 167\n",
            "[2024-11-09 16:24:45,668 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 168\n",
            "[2024-11-09 16:24:52,358 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 169\n",
            "[2024-11-09 16:24:52,505 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 170\n",
            "[2024-11-09 16:24:52,657 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 171\n",
            "[2024-11-09 16:24:59,928 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 172\n",
            "[2024-11-09 16:25:00,077 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 173\n",
            "[2024-11-09 16:25:03,243 INFO] Step 1500/ 4000; acc: 99.3; ppl:   3.5; xent: 1.3; lr: 0.00114; sents:   17362; bsz: 1557/1456/43; 18198/17020 tok/s;    523 sec;\n",
            "[2024-11-09 16:25:03,798 INFO] valid stats calculation\n",
            "                           took: 0.5539383888244629 s.\n",
            "[2024-11-09 16:25:03,799 INFO] Train perplexity: 8.33601\n",
            "[2024-11-09 16:25:03,799 INFO] Train accuracy: 81.423\n",
            "[2024-11-09 16:25:03,799 INFO] Sentences processed: 259980\n",
            "[2024-11-09 16:25:03,799 INFO] Average bsz: 1557/1455/43\n",
            "[2024-11-09 16:25:03,799 INFO] Validation perplexity: 148.974\n",
            "[2024-11-09 16:25:03,799 INFO] Validation accuracy: 38.7184\n",
            "[2024-11-09 16:25:03,799 INFO] Stalled patience: 2/4\n",
            "[2024-11-09 16:25:03,802 INFO] Saving checkpoint models/model.fren_step_1500.pt\n",
            "[2024-11-09 16:25:19,489 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 174\n",
            "[2024-11-09 16:25:19,752 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 175\n",
            "[2024-11-09 16:25:28,368 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 176\n",
            "[2024-11-09 16:25:28,986 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 177\n",
            "[2024-11-09 16:25:29,252 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 178\n",
            "[2024-11-09 16:25:36,797 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 179\n",
            "[2024-11-09 16:25:37,175 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 180\n",
            "[2024-11-09 16:25:43,587 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 181\n",
            "[2024-11-09 16:25:43,941 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 182\n",
            "[2024-11-09 16:25:44,102 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 183\n",
            "[2024-11-09 16:25:50,984 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 184\n",
            "[2024-11-09 16:25:51,356 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 185\n",
            "[2024-11-09 16:25:52,916 INFO] Step 1600/ 4000; acc: 99.3; ppl:   3.5; xent: 1.3; lr: 0.00110; sents:   17276; bsz: 1561/1457/43; 12569/11733 tok/s;    572 sec;\n",
            "[2024-11-09 16:25:57,801 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 186\n",
            "[2024-11-09 16:25:57,947 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 187\n",
            "[2024-11-09 16:26:05,102 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 188\n",
            "[2024-11-09 16:26:05,252 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 189\n",
            "[2024-11-09 16:26:05,661 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 190\n",
            "[2024-11-09 16:26:12,152 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 191\n",
            "[2024-11-09 16:26:12,301 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 192\n",
            "[2024-11-09 16:26:19,588 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 193\n",
            "[2024-11-09 16:26:19,848 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 194\n",
            "[2024-11-09 16:26:20,104 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 195\n",
            "[2024-11-09 16:26:26,801 INFO] Step 1700/ 4000; acc: 99.3; ppl:   3.5; xent: 1.2; lr: 0.00107; sents:   17326; bsz: 1554/1453/43; 18347/17158 tok/s;    606 sec;\n",
            "[2024-11-09 16:26:27,239 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 196\n",
            "[2024-11-09 16:26:27,396 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 197\n",
            "[2024-11-09 16:26:34,709 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 198\n",
            "[2024-11-09 16:26:34,856 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 199\n",
            "[2024-11-09 16:26:41,545 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 200\n",
            "[2024-11-09 16:26:41,795 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 201\n",
            "[2024-11-09 16:26:42,061 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 202\n",
            "[2024-11-09 16:26:49,238 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 203\n",
            "[2024-11-09 16:26:49,400 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 204\n",
            "[2024-11-09 16:26:56,020 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 205\n",
            "[2024-11-09 16:26:56,529 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 206\n",
            "[2024-11-09 16:27:01,782 INFO] Step 1800/ 4000; acc: 99.3; ppl:   3.5; xent: 1.2; lr: 0.00104; sents:   17346; bsz: 1559/1457/43; 17823/16657 tok/s;    641 sec;\n",
            "[2024-11-09 16:27:03,487 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 207\n",
            "[2024-11-09 16:27:03,634 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 208\n",
            "[2024-11-09 16:27:03,990 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 209\n",
            "[2024-11-09 16:27:10,721 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 210\n",
            "[2024-11-09 16:27:11,277 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 211\n",
            "[2024-11-09 16:27:18,062 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 212\n",
            "[2024-11-09 16:27:18,212 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 213\n",
            "[2024-11-09 16:27:18,597 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 214\n",
            "[2024-11-09 16:27:25,564 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 215\n",
            "[2024-11-09 16:27:25,760 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 216\n",
            "[2024-11-09 16:27:32,447 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 217\n",
            "[2024-11-09 16:27:32,598 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 218\n",
            "[2024-11-09 16:27:36,252 INFO] Step 1900/ 4000; acc: 99.4; ppl:   3.5; xent: 1.2; lr: 0.00101; sents:   17398; bsz: 1558/1456/43; 18078/16901 tok/s;    676 sec;\n",
            "[2024-11-09 16:27:39,826 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 219\n",
            "[2024-11-09 16:27:39,974 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 220\n",
            "[2024-11-09 16:27:40,139 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 221\n",
            "[2024-11-09 16:27:46,818 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 222\n",
            "[2024-11-09 16:27:46,973 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 223\n",
            "[2024-11-09 16:27:54,206 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 224\n",
            "[2024-11-09 16:27:54,353 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 225\n",
            "[2024-11-09 16:27:54,505 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 226\n",
            "[2024-11-09 16:28:01,168 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 227\n",
            "[2024-11-09 16:28:01,319 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 228\n",
            "[2024-11-09 16:28:08,438 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 229\n",
            "[2024-11-09 16:28:08,583 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 230\n",
            "[2024-11-09 16:28:10,487 INFO] Step 2000/ 4000; acc: 99.4; ppl:   3.4; xent: 1.2; lr: 0.00099; sents:   17227; bsz: 1558/1455/43; 18209/16995 tok/s;    710 sec;\n",
            "[2024-11-09 16:28:11,025 INFO] valid stats calculation\n",
            "                           took: 0.5373556613922119 s.\n",
            "[2024-11-09 16:28:11,027 INFO] Train perplexity: 6.69676\n",
            "[2024-11-09 16:28:11,027 INFO] Train accuracy: 85.9089\n",
            "[2024-11-09 16:28:11,027 INFO] Sentences processed: 346553\n",
            "[2024-11-09 16:28:11,027 INFO] Average bsz: 1557/1455/43\n",
            "[2024-11-09 16:28:11,027 INFO] Validation perplexity: 155.855\n",
            "[2024-11-09 16:28:11,027 INFO] Validation accuracy: 38.6944\n",
            "[2024-11-09 16:28:11,027 INFO] Stalled patience: 1/4\n",
            "[2024-11-09 16:28:11,030 INFO] Saving checkpoint models/model.fren_step_2000.pt\n",
            "[2024-11-09 16:28:26,905 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 231\n",
            "[2024-11-09 16:28:27,249 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 232\n",
            "[2024-11-09 16:28:27,403 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 233\n",
            "[2024-11-09 16:28:36,772 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 234\n",
            "[2024-11-09 16:28:37,315 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 235\n",
            "[2024-11-09 16:28:44,068 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 236\n",
            "[2024-11-09 16:28:44,231 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 237\n",
            "[2024-11-09 16:28:44,754 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 238\n",
            "[2024-11-09 16:28:51,725 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 239\n",
            "[2024-11-09 16:28:52,111 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 240\n",
            "[2024-11-09 16:28:58,577 INFO] Step 2100/ 4000; acc: 99.4; ppl:   3.4; xent: 1.2; lr: 0.00096; sents:   17347; bsz: 1554/1453/43; 12925/12089 tok/s;    758 sec;\n",
            "[2024-11-09 16:28:58,701 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 241\n",
            "[2024-11-09 16:28:58,957 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 242\n",
            "[2024-11-09 16:29:06,228 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 243\n",
            "[2024-11-09 16:29:06,400 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 244\n",
            "[2024-11-09 16:29:06,560 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 245\n",
            "[2024-11-09 16:29:13,502 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 246\n",
            "[2024-11-09 16:29:13,765 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 247\n",
            "[2024-11-09 16:29:20,835 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 248\n",
            "[2024-11-09 16:29:20,981 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 249\n",
            "[2024-11-09 16:29:21,124 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 250\n",
            "[2024-11-09 16:29:28,191 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 251\n",
            "[2024-11-09 16:29:28,449 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 252\n",
            "[2024-11-09 16:29:33,694 INFO] Step 2200/ 4000; acc: 99.5; ppl:   3.4; xent: 1.2; lr: 0.00094; sents:   17405; bsz: 1558/1457/44; 17751/16597 tok/s;    793 sec;\n",
            "[2024-11-09 16:29:35,162 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 253\n",
            "[2024-11-09 16:29:35,315 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 254\n",
            "[2024-11-09 16:29:42,238 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 255\n",
            "[2024-11-09 16:29:42,589 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 256\n",
            "[2024-11-09 16:29:42,736 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 257\n",
            "[2024-11-09 16:29:49,194 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 258\n",
            "[2024-11-09 16:29:49,553 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 259\n",
            "[2024-11-09 16:29:56,491 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 260\n",
            "[2024-11-09 16:29:56,864 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 261\n",
            "[2024-11-09 16:29:57,010 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 262\n",
            "[2024-11-09 16:30:03,487 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 263\n",
            "[2024-11-09 16:30:03,856 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 264\n",
            "[2024-11-09 16:30:07,607 INFO] Step 2300/ 4000; acc: 99.5; ppl:   3.4; xent: 1.2; lr: 0.00092; sents:   17254; bsz: 1557/1453/43; 18362/17142 tok/s;    827 sec;\n",
            "[2024-11-09 16:30:10,831 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 265\n",
            "[2024-11-09 16:30:10,985 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 266\n",
            "[2024-11-09 16:30:17,666 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 267\n",
            "[2024-11-09 16:30:17,818 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 268\n",
            "[2024-11-09 16:30:17,983 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 269\n",
            "[2024-11-09 16:30:25,126 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 270\n",
            "[2024-11-09 16:30:25,278 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 271\n",
            "[2024-11-09 16:30:31,958 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 272\n",
            "[2024-11-09 16:30:32,103 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 273\n",
            "[2024-11-09 16:30:32,252 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 274\n",
            "[2024-11-09 16:30:39,422 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 275\n",
            "[2024-11-09 16:30:39,575 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 276\n",
            "[2024-11-09 16:30:41,842 INFO] Step 2400/ 4000; acc: 99.5; ppl:   3.4; xent: 1.2; lr: 0.00090; sents:   17223; bsz: 1556/1453/43; 18181/16981 tok/s;    861 sec;\n",
            "[2024-11-09 16:30:46,198 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 277\n",
            "[2024-11-09 16:30:46,351 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 278\n",
            "[2024-11-09 16:30:53,486 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 279\n",
            "[2024-11-09 16:30:53,642 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 280\n",
            "[2024-11-09 16:30:53,799 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 281\n",
            "[2024-11-09 16:31:00,428 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 282\n",
            "[2024-11-09 16:31:00,575 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 283\n",
            "[2024-11-09 16:31:08,490 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 284\n",
            "[2024-11-09 16:31:08,837 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 285\n",
            "[2024-11-09 16:31:08,985 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 286\n",
            "[2024-11-09 16:31:15,476 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 287\n",
            "[2024-11-09 16:31:16,009 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 288\n",
            "[2024-11-09 16:31:17,010 INFO] Step 2500/ 4000; acc: 99.5; ppl:   3.4; xent: 1.2; lr: 0.00088; sents:   17446; bsz: 1557/1457/44; 17704/16574 tok/s;    896 sec;\n",
            "[2024-11-09 16:31:17,725 INFO] valid stats calculation\n",
            "                           took: 0.7125182151794434 s.\n",
            "[2024-11-09 16:31:17,727 INFO] Train perplexity: 5.85384\n",
            "[2024-11-09 16:31:17,727 INFO] Train accuracy: 88.6258\n",
            "[2024-11-09 16:31:17,727 INFO] Sentences processed: 433228\n",
            "[2024-11-09 16:31:17,728 INFO] Average bsz: 1557/1455/43\n",
            "[2024-11-09 16:31:17,728 INFO] Validation perplexity: 166.112\n",
            "[2024-11-09 16:31:17,728 INFO] Validation accuracy: 38.4072\n",
            "[2024-11-09 16:31:17,728 INFO] Stalled patience: 0/4\n",
            "[2024-11-09 16:31:17,728 INFO] Training finished after stalled validations. Early Stop!\n",
            "[2024-11-09 16:31:17,728 INFO] Best model found at step 500\n",
            "[2024-11-09 16:31:17,728 INFO] earlystopper has_stopped!\n",
            "[2024-11-09 16:31:17,806 INFO] Saving checkpoint models/model.fren_step_2500.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkMGOmlEs73G",
        "outputId": "0cb7cc8f-82a4-4afc-87f9-b4103564343c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bible_verses.csv\t\t\t\tMT-Preparation\n",
            "compute-bleu.py\t\t\t\t\tnagamese.csv\n",
            "compute-bleu.py.1\t\t\t\tnagamese.csv-filtered.ng\n",
            "config.yaml\t\t\t\t\tnagamese.csv-filtered.ng.subword\n",
            "english.csv\t\t\t\t\tnagamese.csv-filtered.ng.subword.dev\n",
            "english.csv-filtered.en\t\t\t\tnagamese.csv-filtered.ng.subword.test\n",
            "english.csv-filtered.en.subword\t\t\tnagamese.csv-filtered.ng.subword.test.desubword\n",
            "english.csv-filtered.en.subword.dev\t\tnagamese.csv-filtered.ng.subword.train\n",
            "english.csv-filtered.en.subword.test\t\trun\n",
            "english.csv-filtered.en.subword.test.desubword\tsource.model\n",
            "english.csv-filtered.en.subword.train\t\tsource.vocab\n",
            "en.translated\t\t\t\t\ttarget.model\n",
            "en.translated.desubword\t\t\t\ttarget.vocab\n",
            "models\t\t\t\t\t\ttrain.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Translate the \"subworded\" source file of the test dataset\n",
        "# Change the model name, if needed.\n",
        "!onmt_translate -model models/model.fren_step_2500.pt -src nagamese.csv-filtered.ng.subword.test -output en.translated -gpu 0 -min_length 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdqr-OMAr69U",
        "outputId": "20cbc366-c288-4111-c5ba-a01f20343169"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-11-09 16:31:50,613 INFO] Loading checkpoint from models/model.fren_step_2500.pt\n",
            "[2024-11-09 16:31:52,205 INFO] Loading data into the model\n",
            "[2024-11-09 16:32:01,304 INFO] PRED SCORE: -0.4314, PRED PPL: 1.54 NB SENTENCES: 500\n",
            "Time w/o python interpreter load/terminate:  11.0454421043396\n"
          ]
        }
      ]
    }
  ]
}